{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd831465",
   "metadata": {},
   "source": [
    "# LEOHS (Landsat ETM+ OLI Harmonization Script)\n",
    "This is still being developed, Coded by Galen Richardson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1868a7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd #geospatial libraries\n",
    "from shapely.geometry import Point, box\n",
    "import rasterio,ee,geemap\n",
    "from rasterio.features import geometry_mask\n",
    "from geopy.distance import distance\n",
    "import pandas as pd #basics\n",
    "import numpy as np\n",
    "import warnings,joblib,time,random,re,os,shutil\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt #plotting\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from datetime import datetime\n",
    "from joblib import Parallel, delayed #parallel processing\n",
    "from scipy.stats import gaussian_kde #regression\n",
    "from scipy.odr import ODR, Model, RealData\n",
    "from sklearn.linear_model import LinearRegression,TheilSenRegressor\n",
    "ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3cb1d9",
   "metadata": {},
   "source": [
    "## Variables\n",
    "These Variables are user defined and can be used to customize the output of the tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "519691f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###Define Image collections###\n",
    "LS8 = \"LANDSAT/LC08/C02/T1_L2\"\n",
    "LS7 = \"LANDSAT/LE07/C02/T1_L2\"\n",
    "\n",
    "#LS8 = \"LANDSAT/LC08/C02/T1_TOA\"\n",
    "#LS7 = \"LANDSAT/LE07/C02/T1_TOA\"\n",
    "\n",
    "harmonization_order=[LS7,LS8]\n",
    "#an order of [LS7,LS8] means you will get an equation for making LS7 look like LS8\n",
    "\n",
    "Aoi_shp_path= r'E:\\GIS\\CFS_FFF\\AOIs\\FFF_AOI.shp'\n",
    "#AOI shapefile for the region you want to create normalization coeficients for\n",
    "#Perfomance might be lower on AOI's that cover less than 10 WRS tiles\n",
    "\n",
    "Load_sample_points=False\n",
    "sample_points_path=r'E:\\GIS\\Landsat Normalization\\Paper_results\\Sample_points\\1000000_sample_points.shp'\n",
    "\n",
    "wrs_shp_path=r'E:\\GIS\\Landsat Normalization\\Landsat_WRS_index\\WRS_overlaps.shp'\n",
    "#This is the link to WRS_overlaps.shp. It is necessary for finding overlaps\n",
    "\n",
    "Save_data=True\n",
    "Save_folder_path=r'E:\\GIS\\Lichen_work_master\\Harmonization\\QCLBSR50cc_m78_ally_deep_no_watersnow'\n",
    "\n",
    "months=[7,8]#needs to be a list of months\n",
    "#[1,2,3,4,5,6,7,8,9,10,11,12] is full range of months\n",
    "years=[2013,2014,2015,2016,2017,2018,2019,2020,2021,2022]#needs to be a list of years\n",
    "#[2013,2014,2015,2016,2017,2018,2019,2020,2021,2022] is full range of years\n",
    "\n",
    "maxCloudCover=50 #maximum cloud coverage per Landsat image\n",
    "\n",
    "CFMask_filtering=True #used to enable CFMask filtering\n",
    "Water= False #if you want to include Water Pixels (CFMask), Set to True (yes) or False (no)\n",
    "Snow= False #if you want to include Snow pixels (CFMask), Set to True (yes) or False (no)\n",
    "\n",
    "Max_img_samples=10 #max number of images sampled between LS7 and LS8 overlap\n",
    "\n",
    "Pixel_difference=1 #discarding pixels that are 100% different (same EQ as Roy et al)\n",
    "#this is the maximum difference between LS7 and LS8 pixels allowed\n",
    "#if the scatterplots look weird, or there is smoke in imagery, set to a lower value like .5 for 50% different\n",
    "\n",
    "sample_points_n=1000000 #max is 1,000,000 points\n",
    "#number of random sample points to generate\n",
    "\n",
    "Regression_types=[\"OLS\",\"RMA\",\"TheilSen\"]\n",
    "#[\"OLS\",\"RMA\",\"TheilSen\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ebde7b",
   "metadata": {},
   "source": [
    "These functions are necessary for the script to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db922904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_cores=min(joblib.cpu_count(), 16)-2\n",
    "def time_tracker(start_time):\n",
    "    return \"{}sec\".format(round((datetime.now() - start_time).total_seconds(), 2))\n",
    "def get_var_names_from_list(in_list):\n",
    "    # Create a mapping from values to variable names\n",
    "    value_to_name = {value: name for name, value in globals().items() if isinstance(value, str)}\n",
    "    # Use this mapping to retrieve the variable names in the order of in_list\n",
    "    return [value_to_name[value] for value in in_list if value in value_to_name]\n",
    "def apply_correction_factors (LS8,LS7,gdf):\n",
    "    if \"TOA\" in LS8 and \"TOA\" in LS7:\n",
    "        return gdf\n",
    "    elif \"TOA\" not in LS8 and \"TOA\" not in LS7:\n",
    "        columns_to_transform=[col for col in gdf.columns if col not in ['L1_image_id','L2_image_id','geometry']]\n",
    "        gdf[columns_to_transform]=gdf[columns_to_transform]*0.0000275 - 0.2\n",
    "        return gdf\n",
    "    else:\n",
    "        print('ERROR!!! TOA and SR datasets selected')\n",
    "def toa_or_sr (LS8,LS7):\n",
    "    if \"toa\" in LS8.lower() and \"toa\" in LS7.lower():\n",
    "        return \"TOA\"\n",
    "    if \"toa\" in LS8.lower() or \"toa\" in LS7.lower():\n",
    "        return \"Non-Matching\"\n",
    "    else:\n",
    "        return \"SR\"\n",
    "def create_save_path():\n",
    "    if Save_data==True: #remakes Save_folder_path\n",
    "        if os.path.exists(Save_folder_path):\n",
    "            shutil.rmtree(Save_folder_path)\n",
    "        os.makedirs(Save_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f737c78a",
   "metadata": {},
   "source": [
    "## Step 1. Create Overlap DF and Frequency Map\n",
    "This step determines if the area of interest is too large to process as a whole in GEE, where if True it would be broken up into strips.Then, the AOI or strips of AOI are passed into GEE, and all the LS7 and LS8 image names that intersect and are within the time and cloud coverage queries are selected. String manipulation is used to get the path/row and date of each image. overlap_df is created by finding overlapes between LS7 and LS8 which are +/- 1 day and +/- 1 path. This is then grouped and counted to create frequency_gdf which shows the number of overlapping LS7 nand LS8 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ebbc1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_WRS_gdf(input_shp, WRS_shapefile):\n",
    "    create_save_path()\n",
    "    #this creates a gdf of only WRS tiles found in the shapefile\n",
    "    full_AOI=gpd.read_file(input_shp)\n",
    "    full_AOI=full_AOI.to_crs('EPSG:4326')  # Ensure CRS is set to EPSG:4326\n",
    "    full_AOI['geometry']=full_AOI.geometry.buffer(0)\n",
    "    wrsgdf=gpd.read_file(WRS_shapefile)\n",
    "    wrsgdf=wrsgdf.to_crs('EPSG:4326')\n",
    "    wrsgdf['geometry']=wrsgdf.geometry.buffer(0)\n",
    "    overlap_wrs=gpd.sjoin(wrsgdf,full_AOI,how=\"inner\",predicate='intersects')\n",
    "    df_subset=overlap_wrs[['row1','path1','path2','geometry']].reset_index(drop=True)\n",
    "    return df_subset,full_AOI\n",
    "def split_aoi_into_strips(gdf, max_area=1e13):\n",
    "    projected_gdf=gdf.to_crs('EPSG:8857')  # Project to equal area for calculation\n",
    "    total_area=projected_gdf.geometry.area.sum()  # Calculate area\n",
    "    if total_area<max_area:\n",
    "        print('No need for splitting. Starting timer and proceeding.')\n",
    "        return gdf, None\n",
    "    minx,miny,maxx,maxy=gdf.total_bounds\n",
    "    midy=(miny+maxy)/2  # Calculate the midpoint y-coordinate, make upper and lower strips\n",
    "    upper_strip,lower_strip=box(minx,midy,maxx,maxy),box(minx,miny,maxx,midy)\n",
    "    upper_gdf=gpd.overlay(gdf,gpd.GeoDataFrame(geometry=[upper_strip],crs='EPSG:4326'),how='intersection')\n",
    "    lower_gdf=gpd.overlay(gdf,gpd.GeoDataFrame(geometry=[lower_strip],crs='EPSG:4326'),how='intersection')\n",
    "    num_strips=int(np.ceil(total_area/max_area))# Determine the number of strips needed based on the area\n",
    "    strips=[]\n",
    "    strip_width=(maxx-minx)/num_strips \n",
    "    for i in range(num_strips):\n",
    "        strip_minx=minx+i*strip_width\n",
    "        strip_maxx=minx+(i+ 1)*strip_width\n",
    "        upper_vertical_strip=box(strip_minx, midy, strip_maxx, maxy)# Process upper strip\n",
    "        upper_strip_gdf=gpd.overlay(upper_gdf, gpd.GeoDataFrame(geometry=[upper_vertical_strip], crs='EPSG:4326'), how='intersection')\n",
    "        strips.append(upper_strip_gdf)\n",
    "        lower_vertical_strip=box(strip_minx, miny, strip_maxx, midy)# Process lower strip\n",
    "        lower_strip_gdf=gpd.overlay(lower_gdf, gpd.GeoDataFrame(geometry=[lower_vertical_strip], crs='EPSG:4326'), how='intersection')\n",
    "        strips.append(lower_strip_gdf)\n",
    "    strips=[df for df in strips if not df.empty]\n",
    "    print(f'{len(strips)} Strips created due to input AOI size. Starting timer and Proceeding.')\n",
    "    return gdf, strips\n",
    "def date_cloud_aoi_filter(Landsatcollection,month,year,aoi):\n",
    "    #basic filters based on month, year, cloud coverage, and AOI\n",
    "    return Landsatcollection\\\n",
    "    .filter(ee.Filter.calendarRange(month, month, 'month')).filter(ee.Filter.calendarRange(year, year, 'year')) \\\n",
    "    .filter(ee.Filter.lte('CLOUD_COVER',maxCloudCover))\\\n",
    "    .filterBounds(aoi)\n",
    "def get_image_names(image_collection):\n",
    "    image_ids=image_collection.aggregate_array('system:id').getInfo()\n",
    "    return image_ids\n",
    "def extract_date_path_row(image_id):\n",
    "    #used to extract date,path,row from landsat image name\n",
    "    date_str=image_id.split('_')[-1]\n",
    "    row,path=int(image_id.split('_')[-2][3:6]),int(image_id.split('_')[-2][:3])\n",
    "    return datetime.strptime(date_str,'%Y%m%d'),row,path\n",
    "def process_names(image_names):\n",
    "    name_list=[]\n",
    "    df=None #process the names and make a df from list of image names\n",
    "    for name in image_names:\n",
    "        date, row, path=extract_date_path_row(name)\n",
    "        detailed_name=[name,date, row, path]\n",
    "        name_list.append(detailed_name)\n",
    "        df=pd.DataFrame(name_list)\n",
    "        df.columns=['id', 'date', 'row','path']\n",
    "        df[['row', 'path']]=df[['row', 'path']].astype(int)\n",
    "    if df is not None:\n",
    "        return df\n",
    "def cycle_through_image_names(LS1, LS2, aoi):\n",
    "    aoi=geemap.geopandas_to_ee(aoi)\n",
    "    matching_pairs=[]\n",
    "    L1_df,L2_df=None, None\n",
    "    for year in years:\n",
    "        for month in months:\n",
    "            L1_SR=date_cloud_aoi_filter(ee.ImageCollection(LS1),month,year,aoi)  # filter date, cloud, aoi\n",
    "            L2_SR=date_cloud_aoi_filter(ee.ImageCollection(LS2),month,year,aoi)\n",
    "            L1_names,L2_names=get_image_names(L1_SR),get_image_names(L2_SR)  # get names of all the images that are within the filter\n",
    "            L1_df,L2_df=process_names(L1_names), process_names(L2_names)  # process the names using string manipulation and make into a df\n",
    "            if L1_df is not None and not L1_df.empty and L2_df is not None and not L2_df.empty:  # not empty dfs or ones that do not exist\n",
    "                for index_L1,row_L1 in L1_df.iterrows():\n",
    "                    # Find rows in L2_df with the same 'row' and 'path' within +1 or -1, and date within 1 day\n",
    "                    possible_1row_matches=L2_df[(L2_df['row']==row_L1['row']) &\n",
    "                        ((L2_df['path']==row_L1['path'] + 1) | (L2_df['path']==row_L1['path'] - 1)) &\n",
    "                        (abs(L2_df['date']-row_L1['date']).dt.days<= 1)]  # this is the formula for finding matches\n",
    "                    for index_L2, row_L2 in possible_1row_matches.iterrows():\n",
    "                        matching_pairs.append({'L1_id': row_L1['id'], 'L1_date': row_L1['date'], 'L1_row': row_L1['row'], 'L1_path': row_L1['path'],'L2_id': row_L2['id'], 'L2_date': row_L2['date'], 'L2_row': row_L2['row'], 'L2_path': row_L2['path']})\n",
    "                    # Find rows in L2_df with same 'row' and edge paths within +1 or -1 date\n",
    "                    possible_edge_matches=L2_df[(L2_df['row']==row_L1['row']) &\n",
    "                        ((L2_df['path']==row_L1['path'] + 232) | (L2_df['path']==row_L1['path'] - 232)) &\n",
    "                        (abs(L2_df['date']-row_L1['date']).dt.days<= 1)]  # this is the formula for finding matches\n",
    "                    for index_L2, row_L2 in possible_edge_matches.iterrows():\n",
    "                        matching_pairs.append({'L1_id': row_L1['id'], 'L1_date': row_L1['date'], 'L1_row': row_L1['row'], 'L1_path': row_L1['path'],'L2_id': row_L2['id'], 'L2_date': row_L2['date'], 'L2_row': row_L2['row'], 'L2_path': row_L2['path']})\n",
    "    return matching_pairs\n",
    "def chunk_list(lst,n):\n",
    "    avg, out, last=len(lst) / float(n),[],0.0 #Divide a list into `n` chunks.\n",
    "    while last<len(lst):\n",
    "        out.append(lst[int(last):int(last + avg)])\n",
    "        last+=avg\n",
    "    return out\n",
    "def process_strip_chunk(LS1,LS2,strips_chunk,chunk_index):\n",
    "    all_matching_pairs=[]\n",
    "    ee.Initialize()\n",
    "    for strip_n,strip in enumerate(strips_chunk):\n",
    "        strip_time=datetime.now()\n",
    "        matching_pairs=cycle_through_image_names(LS1,LS2,strip)\n",
    "        all_matching_pairs.extend(matching_pairs)\n",
    "        matching_df=pd.DataFrame(all_matching_pairs).drop_duplicates(inplace=False)\n",
    "    return all_matching_pairs\n",
    "def saving_overlap_info(frequency_gdf,matching_df):\n",
    "    dtype=toa_or_sr(LS8,LS7)\n",
    "    col_names=get_var_names_from_list(harmonization_order)\n",
    "    frequency_gdf.to_file(f'{Save_folder_path}\\\\frequencey_gdf.shp', driver='ESRI Shapefile')\n",
    "    frequency_gdf.plot(column='count_gee',cmap='viridis', legend=False)\n",
    "    plt.title(f'Frequency of {dtype} {col_names[0]} and {col_names[1]} Overlaps', fontsize=16)\n",
    "    plt.savefig(f'{Save_folder_path}\\\\frequencey_plot.png',dpi=500)\n",
    "    matching_df.to_csv(f'{Save_folder_path}\\\\overlap.csv')\n",
    "def create_overlap_df(harmonization_order, aoi, strips):\n",
    "    print(f'{toa_or_sr(LS8,LS7)} imagery datasets')#used to print to user what imagery dataset they are using\n",
    "    LS1, LS2=ee.ImageCollection(harmonization_order[0]),ee.ImageCollection(harmonization_order[1])#order of harmonization\n",
    "    start_time=datetime.now()\n",
    "    if strips is None:\n",
    "        matching_pairs=cycle_through_image_names(LS1, LS2, aoi)\n",
    "        overlap_df=pd.DataFrame(matching_pairs)\n",
    "    else:\n",
    "        print(f'Processing {len(strips)} strips')\n",
    "        chunks=chunk_list(strips, num_cores)# Split the strips list into smaller chunks for parallel processing\n",
    "        results=Parallel(n_jobs=num_cores)(\n",
    "            delayed(process_strip_chunk)(LS1, LS2, chunk, idx) for idx, chunk in enumerate(chunks))\n",
    "        all_matching_pairs=[pair for result in results for pair in result]# Combine results from all chunks\n",
    "        overlap_df=pd.DataFrame(all_matching_pairs)\n",
    "        overlap_df.drop_duplicates(inplace=True)\n",
    "    print(f\"GEE filtering completed in {time_tracker(start_time)}\")\n",
    "    if overlap_df.empty:\n",
    "        print(\"No matches available\")\n",
    "        return None, None\n",
    "    grouped_df=overlap_df.groupby(['L1_row','L1_path','L2_path']).size().reset_index(name='count_gee')#create frequency_GDF\n",
    "    frequency_gdf=pd.merge(grouped_df, WRS_gdf, left_on=['L1_row','L1_path','L2_path'], right_on=['row1','path1','path2'], how='inner')\n",
    "    if frequency_gdf.empty:\n",
    "        print(\"No matches available\")\n",
    "        return None, None\n",
    "    frequency_gdf=gpd.GeoDataFrame(frequency_gdf,geometry='geometry')\n",
    "    frequency_gdf.crs='EPSG:4326'\n",
    "    frequency_gdf = frequency_gdf.drop_duplicates(subset='geometry')#get rid of duplicates\n",
    "    if Save_data==True:\n",
    "        saving_overlap_info(frequency_gdf,overlap_df)\n",
    "    return overlap_df,frequency_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8fba45",
   "metadata": {},
   "source": [
    "## Step 2. Create Sample Points within AOI\n",
    "This sections projects the AOI into an equal earth projection and randomly generates sample_points_n points within it. For points that do not land within a LS7/LS8 overlap, the point is moved to the nearest overlap and then randomly assigned a location within the polygon. The output (overlap_points_gdf) contains all the points that will be sampled in Step 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73b364a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_equalA_points (AOI,points_n):\n",
    "    AOI=AOI.to_crs('EPSG:8857')#make into equal earth projection for even global sampling\n",
    "    transform=rasterio.transform.from_bounds(*AOI.total_bounds,10000,10000)#creates a raster grid\n",
    "    mask=geometry_mask([geom for geom in AOI.geometry], transform=transform, invert=True, out_shape=(10000,10000))#creates masked raster grid\n",
    "    rows, cols=np.where(mask)#Sample points from the mask raster grid\n",
    "    random_indices=np.random.choice(len(rows), size=points_n, replace=False)\n",
    "    sampled_rows,sampled_cols=rows[random_indices],cols[random_indices]\n",
    "    x_coords, y_coords=rasterio.transform.xy(transform, sampled_rows, sampled_cols)\n",
    "    points=[Point(x, y) for x, y in zip(x_coords, y_coords)]#Create points from the sampled coordinates\n",
    "    points_gdf=gpd.GeoDataFrame(geometry=points, crs='EPSG:8857')\n",
    "    print('Initial points generated, ensuring they are in WRS overlaps')\n",
    "    return points_gdf\n",
    "def find_nearest_polygon_and_generate_point(WRS_gdf, point):\n",
    "    point = gpd.GeoSeries([point], crs=WRS_gdf.crs)#Ensure the point is in the same CRS as the polygons and AOI\n",
    "    WRS_gdf['distance']=WRS_gdf['geometry'].distance(point.iloc[0])#Calculate the distance from the point to each polygon in WRS_gdf\n",
    "    nearest_polygon=WRS_gdf.loc[WRS_gdf['distance'].idxmin()]['geometry']#Find the polygon with the minimum distance\n",
    "    minx, miny, maxx, maxy=nearest_polygon.bounds #Generate a random point within the intersection polygon\n",
    "    while True:\n",
    "        random_point=Point(random.uniform(minx, maxx), random.uniform(miny, maxy))\n",
    "        if nearest_polygon.contains(random_point):\n",
    "            return random_point\n",
    "def process_points(aoi_points,overlap_gdf):\n",
    "    start_time=datetime.now()\n",
    "    overlap_gdf=overlap_gdf.to_crs('EPSG:8857')#Project to equal earth\n",
    "    new_points=[]\n",
    "    AOI_array=np.array([(point.x, point.y) for point in aoi_points.geometry])#Make AOI array for distance calculations\n",
    "    for point_array in AOI_array:\n",
    "        point=Point(point_array[0], point_array[1])\n",
    "        if overlap_gdf.contains(point).any():\n",
    "            new_points.append(point)#Append point if it is inside a WRS tile\n",
    "        else:\n",
    "            alt_point=find_nearest_polygon_and_generate_point(overlap_gdf, point)#If not, find closest alternative\n",
    "            new_points.append(alt_point)#Append the alt point to the list directly\n",
    "    return gpd.GeoDataFrame(geometry=new_points, crs='EPSG:8857')\n",
    "def parallel_process_points(aoi_points,frequency_gdf,full_AOI):\n",
    "    start_time=datetime.now()\n",
    "    full_AOI=full_AOI.to_crs('EPSG:8857')\n",
    "    frequency_gdf=frequency_gdf.to_crs('EPSG:8857')\n",
    "    clip_gdf=gpd.clip(frequency_gdf, full_AOI) #clipping frequency_gdf to AOI\n",
    "    clip_gdf=clip_gdf.to_crs('EPSG:8857') # making it equal area\n",
    "    clip_gdf=clip_gdf.explode().reset_index(drop=True) #removing multipolygons\n",
    "    point_count=len(aoi_points)\n",
    "    subset_size=max(point_count // num_cores, 1)\n",
    "    aoi_subsets=[aoi_points.iloc[i:i + subset_size] for i in range(0, point_count, subset_size)]\n",
    "    results=Parallel(n_jobs=num_cores)(\n",
    "        delayed(process_points)(aoi_subset, clip_gdf) for aoi_subset in aoi_subsets)\n",
    "    combined_gdf=gpd.GeoDataFrame(pd.concat(results, ignore_index=True))\n",
    "    combined_gdf=combined_gdf.to_crs('EPSG:4326')#Convert back to WGS 84\n",
    "    if Save_data==True:\n",
    "        combined_gdf.to_file(f'{Save_folder_path}\\\\{sample_points_n}_sample_points.shp', driver='ESRI Shapefile')\n",
    "    print(f'Processed in {time_tracker(start_time)}')\n",
    "    return combined_gdf\n",
    "def create_overlap_points_gdf(points_gdf,wrs_gdf):\n",
    "    points_gdf=points_gdf.to_crs(wrs_gdf.crs) #appends path/row information to points\n",
    "    joined_gdf=gpd.overlay(points_gdf, wrs_gdf[['geometry','L1_row','L1_path','L2_path']], how='intersection')# Perform the spatial join using 'overlap'\n",
    "    joined_gdf=joined_gdf[['L1_row','L1_path','L2_path','geometry']].drop_duplicates(subset='geometry') # Clean up the resulting GeoDataFrame\n",
    "    return joined_gdf.reset_index(drop=True).drop_duplicates()\n",
    "def run_workflow(full_AOI,sample_points_n,frequency_gdf,Load_sample_points,sample_points_path):\n",
    "    if Load_sample_points==True:\n",
    "        Sample_points_gdf = gpd.read_file(sample_points_path)\n",
    "        overlap_points_gdf=create_overlap_points_gdf(Sample_points_gdf,frequency_gdf)\n",
    "        print('Loaded sample points')\n",
    "    else:\n",
    "        AOI_points=generate_equalA_points(full_AOI,sample_points_n)#makes random points in equal earth prj\n",
    "        Sample_points_gdf=parallel_process_points(AOI_points,frequency_gdf,full_AOI)#moves points inside WRS tiles\n",
    "        overlap_points_gdf=create_overlap_points_gdf(Sample_points_gdf,frequency_gdf)#appends path/row information to points\n",
    "    return Sample_points_gdf,overlap_points_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43071f37",
   "metadata": {},
   "source": [
    "## Step 3. Create GDF containing pixel values\n",
    "The objective of this part of the script is to use overlap_points_gdf to sample pixel values found LS7 and LS8 Gee imagery. Max_img_samples is the number of image pairs are selected for each LS7/LS8 overlap. Once a point has a clear observation in both LS7 and LS8 images (and complies with Pixel_difference between LS7/LS8), it is added to big_gdf and removed from further sampling. The output from this section, big_gdf, contains the pixel values for both LS7 and LS8 sensors, the image names, and the location of the point that was sampled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9587a87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7763e32c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dc6353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0020c4d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
